{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, brier_score_loss, make_scorer\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, sem\n",
    "import scipy.stats\n",
    "import os\n",
    "from ehr_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/blhill/paper\"\n",
    "pred_probs_f = \"model_pred_probs.txt\"\n",
    "\n",
    "dnn_pred_probs_f = \"/home/nrakocz/EhrMain/predictions_proba.csv\"\n",
    "# files with predicted probability of death for each input feature set\n",
    "# cols should look like: ADMSN_ID INPT_DEATH_YN PRED_DEATH_ELASTICNET PRED_DEATH_LOGREG PRED_DEATH_RF PRED_DEATH_XGB\n",
    "onlyASA_probs_f = os.path.join(output_dir, os.path.join(\"asa\", pred_probs_f))\n",
    "preopASA_probs_f = os.path.join(output_dir, os.path.join(\"preop_asa\", pred_probs_f))\n",
    "predASA_probs_f = os.path.join(output_dir, os.path.join(\"preop_imp_asa\", pred_probs_f))\n",
    "charlson_probs_f = os.path.join(output_dir, os.path.join(\"charlson\", pred_probs_f))\n",
    "preop_probs_f = os.path.join(output_dir, os.path.join(\"preop\", pred_probs_f))\n",
    "\n",
    "preopASA_probs_notime_f = os.path.join(output_dir, os.path.join(\"preop_asa_no_lab_times\", pred_probs_f))\n",
    "predASA_probs_notime_f = os.path.join(output_dir, os.path.join(\"preop_imp_asa_no_lab_times\", pred_probs_f))\n",
    "preop_probs_notime_f = os.path.join(output_dir, os.path.join(\"preop_no_lab_times\", pred_probs_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into pandas data frame\n",
    "onlyASA_df = pd.read_csv(onlyASA_probs_f, sep=\"\\t\", header=0)\n",
    "preopASA_df = pd.read_csv(preopASA_probs_f, sep=\"\\t\", header=0)\n",
    "predASA_df = pd.read_csv(predASA_probs_f, sep=\"\\t\", header=0)\n",
    "charlson_df = pd.read_csv(charlson_probs_f, sep=\"\\t\", header=0)\n",
    "preop_df = pd.read_csv(preop_probs_f, sep=\"\\t\", header=0)\n",
    "\n",
    "preopASA_notime_df = pd.read_csv(preopASA_probs_notime_f, sep=\"\\t\", header=0)\n",
    "predASA_notime_df = pd.read_csv(predASA_probs_notime_f, sep=\"\\t\", header=0)\n",
    "preop_notime_df = pd.read_csv(preop_probs_notime_f, sep=\"\\t\", header=0)\n",
    "\n",
    "dnn_df = pd.read_csv(dnn_pred_probs_f, sep=\",\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preop_v2_f = os.path.join(output_dir, \"preop/model_pred_probs_v2.txt\")\n",
    "preop_v2_df = pd.read_csv(preop_v2_f, sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the configurations for comparing the AUROCs for different models\n",
    "# choose the models to compare\n",
    "model_name_1 = \"Random Forest\"\n",
    "model_name_2 = \"Random Forest\"\n",
    "# and choose the corresponding datasets to compare (model_name_1 goes with df1, similarly for 2)\n",
    "df1 = predASA_df\n",
    "df2 = preopASA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9392901388096904, 0.9384445205568333, 0.9228757388590025, 0.9307884675433361, 0.9158663260962112]\n",
      "[0.9420695005574226, 0.9422091345615041, 0.9290515090275998, 0.937730798181222, 0.924556026080527]\n",
      "A_1: 0.929453038373 (SE_1: 0.00403612828003)\n",
      "A_2: 0.935123393682 (SE_2: 0.00318616838249)\n"
     ]
    }
   ],
   "source": [
    "roc_auc_vec_1 = []\n",
    "roc_auc_vec_2 = []\n",
    "# for each fold from cross-validation, get AUROC for each model\n",
    "for name, group in df1.groupby(\"test_index\"):\n",
    "    roc_auc_vec_1.append(roc_auc_score(group[\"INPT_DEATH_YN\"], group[model_name_1]))\n",
    "for name, group in df2.groupby(\"test_index\"): \n",
    "    roc_auc_vec_2.append(roc_auc_score(group[\"INPT_DEATH_YN\"], group[model_name_2]))\n",
    "    \n",
    "print roc_auc_vec_1\n",
    "print roc_auc_vec_2\n",
    "\n",
    "A_1 = np.mean(roc_auc_vec_1)\n",
    "A_2 = np.mean(roc_auc_vec_2)\n",
    "SE_1 = sem(roc_auc_vec_1, ddof=0)\n",
    "SE_2 = sem(roc_auc_vec_2, ddof=0)\n",
    "print \"A_1: {} (SE_1: {})\".format(A_1, SE_1)\n",
    "print \"A_2: {} (SE_2: {})\".format(A_2, SE_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004036128280031662\n",
      "0.003186168382492256\n"
     ]
    }
   ],
   "source": [
    "print(np.std(roc_auc_vec_1)/np.sqrt(len(roc_auc_vec_1)))\n",
    "print(np.std(roc_auc_vec_2)/np.sqrt(len(roc_auc_vec_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9169242504293963, 0.9419818263166334)\n",
      "(0.9252330172497656, 0.9450137701135444)\n"
     ]
    }
   ],
   "source": [
    "def ci(results):\n",
    "    return scipy.stats.t.interval(0.95, len(results)-1, loc=np.mean(results), scale=scipy.stats.sem(results))\n",
    "\n",
    "print(ci(roc_auc_vec_1))\n",
    "print(ci(roc_auc_vec_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58575, 9)\n",
      "(58575, 9)\n",
      "(1103, 9)\n",
      "(1103, 9)\n",
      "r_controls: 0.9760734870965603\n",
      "r_cases: 0.9741962258156045\n",
      "avg r:\t\t0.9751348564560824\n",
      "avg AUROC:\t0.9322882160273349\n",
      "now use average r and average AUROC to look up r value from Hanley & McNeil (1983) paper table\n"
     ]
    }
   ],
   "source": [
    "controls_df_1 = df1[df1[\"INPT_DEATH_YN\"] == False]\n",
    "controls_df_2 = df2[df2[\"INPT_DEATH_YN\"] == False]\n",
    "cases_df_1 = df1[df1[\"INPT_DEATH_YN\"] == True]\n",
    "cases_df_2 = df2[df2[\"INPT_DEATH_YN\"] == True]\n",
    "print controls_df_1.shape\n",
    "print controls_df_2.shape\n",
    "print cases_df_1.shape\n",
    "print cases_df_2.shape\n",
    "# calculate correlation between predictions of cases\n",
    "r_controls = pearsonr(controls_df_1[model_name_1], controls_df_2[model_name_2])[0]\n",
    "print \"r_controls:\", r_controls\n",
    "# calculate correlation between predictions of cases\n",
    "r_cases = pearsonr(cases_df_1[model_name_1], cases_df_2[model_name_2])[0]\n",
    "print \"r_cases:\", r_cases\n",
    "avg_r = (r_controls + r_cases) / 2.0\n",
    "print \"avg r:\\t\\t\", avg_r\n",
    "print \"avg AUROC:\\t\", (A_1 + A_2) / 2.0\n",
    "print \"now use average r and average AUROC to look up r value from Hanley & McNeil (1983) paper table\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the table I extrapolated frm the Hanley & McNeil (1983) paper\n",
    "\n",
    "\n",
    "| average correlation between ratings  | Average Area 0.925  | Average Area 0.950 |\n",
    "| :-------------: |:-------------:| :-------------:| \n",
    "| 0.90 | 0.85 | 0.84 | \n",
    "| 0.92 | 0.87 | 0.86 | \n",
    "| 0.94 | 0.90 | 0.89 |\n",
    "| 0.96 | 0.92 | 0.92 | \n",
    "| 0.98 | 0.95 | 0.94 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get this value from the Hanley & McNeil (1983) paper using above values, or \n",
    "# from the table I created above if avg r > 0.90\n",
    "r = 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $z = \\frac{A_1-A_2}{\\sqrt{SE_{1}^{2}+SE_{2}^{2} - 2rSE_1 SE_2}}$\n",
    "where $A_1$ and $SE_1$ refer to the observed area and estimated standard error of the ROC area associated with model 1, similarly for 2, and $r$ is the estimated correlation between $A_1$ and $A_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z(A_1, A_2, SE_1, SE_2, r):\n",
    "    return (A_1 - A_2)/(np.sqrt((SE_1**2) + (SE_2**2) - 2*r*SE_1*SE_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: -3.76719486234 (p=0.000165092138404)\n"
     ]
    }
   ],
   "source": [
    "z_value = z(A_1, A_2, SE_1, SE_2, r)\n",
    "p_value = scipy.stats.norm.sf(abs(z_value))*2 # two sided test\n",
    "print \"z: {} (p={})\".format(z_value, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ehr]",
   "language": "python",
   "name": "conda-env-ehr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
